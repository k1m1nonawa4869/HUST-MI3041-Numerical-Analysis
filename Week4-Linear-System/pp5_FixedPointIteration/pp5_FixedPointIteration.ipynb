{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4ce16862",
   "metadata": {},
   "source": [
    "Phương pháp lặp đơn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4013dff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "pd.set_option('display.precision', 15)  # Increase decimal precision\n",
    "pd.set_option('display.width', 150)     # Wider display\n",
    "pd.set_option('display.max_columns', None)  # Show all column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7ec97cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_matrix_from_file(filename):\n",
    "    \"\"\"\n",
    "    Read a matrix from a text file and display it.\n",
    "    \n",
    "    Parameters:\n",
    "    filename (str): Path to the text file containing the matrix\n",
    "    \n",
    "    Returns:\n",
    "    numpy.ndarray: The matrix read from the file\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Read the matrix from the file\n",
    "        matrix = np.loadtxt(filename)\n",
    "        \n",
    "        # Display the matrix\n",
    "        print(\"Matrix read from file:\")\n",
    "        print(matrix)\n",
    "        \n",
    "        return matrix\n",
    "    \n",
    "    except FileNotFoundError:\n",
    "        print(f\"Error: File '{filename}' not found.\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"Error reading file: {str(e)}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7bfb4d5e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix read from file:\n",
      "[[0.1588 0.0064 0.0025 0.0304 0.0014 0.0083 0.1594]\n",
      " [0.0057 0.2645 0.0436 0.0099 0.0083 0.0201 0.3413]\n",
      " [0.0264 0.1506 0.3557 0.0139 0.0142 0.007  0.0236]\n",
      " [0.3299 0.0565 0.0495 0.3636 0.0204 0.0483 0.0649]\n",
      " [0.0089 0.0081 0.0333 0.0295 0.3412 0.0237 0.002 ]\n",
      " [0.119  0.0901 0.0996 0.126  0.1722 0.2368 0.3369]\n",
      " [0.0063 0.0126 0.0196 0.0098 0.0064 0.0132 0.0012]]\n",
      "Matrix read from file:\n",
      "[ 74000.  56000.  10500.  25000.  17500. 196000.   5000.]\n"
     ]
    }
   ],
   "source": [
    "B = read_matrix_from_file('FXP_input_A.txt')\n",
    "d = read_matrix_from_file('FXP_input_B.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "82109180",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fixed_point_matrix_iteration(A, B, initial_values, q, eps, norm=1):\n",
    "    \"\"\"\n",
    "    Perform fixed-point iteration for system of linear equations using x_new = Ax + B\n",
    "    \n",
    "    Parameters:\n",
    "    A (numpy.ndarray): Coefficient matrix\n",
    "    B (numpy.ndarray): Constant vector\n",
    "    initial_values (numpy.ndarray): Initial guess for x\n",
    "    q (float): Contraction coefficient\n",
    "    eps (float): Tolerance for convergence\n",
    "    norm (int): Type of norm to use (1 for L1 norm, -1 for max norm)\n",
    "    \n",
    "    Returns:\n",
    "    numpy.ndarray: Solution vector\n",
    "    \"\"\"\n",
    "    n = len(initial_values)\n",
    "    values = np.array(initial_values)\n",
    "    results = [[0] + initial_values.tolist()]\n",
    "    i = 0\n",
    "\n",
    "    new_eps = eps * (1-q) / q\n",
    "    print(f\"new_eps: {new_eps}\")\n",
    "\n",
    "    while True:\n",
    "        # Calculate new values using matrix operation x_new = Ax + B\n",
    "        new_values = np.dot(A, values) + B\n",
    "        \n",
    "        # Calculate the differences\n",
    "        diffs = np.abs(new_values - values)\n",
    "        if norm == 1:\n",
    "            total_diff = np.sum(diffs)\n",
    "        elif norm == -1:\n",
    "            total_diff = np.max(diffs)\n",
    "        \n",
    "        # Append results\n",
    "        results.append([i+1] + new_values.tolist() + diffs.tolist() + [total_diff])\n",
    "        values = new_values\n",
    "        \n",
    "        # Check for convergence\n",
    "        if total_diff < new_eps:\n",
    "            break\n",
    "        i += 1\n",
    "        \n",
    "    columns = ['Iteration'] + [f'x{j+1}' for j in range(n)] + [f'diff_x{j+1}' for j in range(n)] + ['total_diff']\n",
    "    df = pd.DataFrame(results, columns=columns)\n",
    "    print(df.to_string(index=False))\n",
    "    \n",
    "    return values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c413fd2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matrix read from file:\n",
      "[[0.1588 0.0064 0.0025 0.0304 0.0014 0.0083 0.1594]\n",
      " [0.0057 0.2645 0.0436 0.0099 0.0083 0.0201 0.3413]\n",
      " [0.0264 0.1506 0.3557 0.0139 0.0142 0.007  0.0236]\n",
      " [0.3299 0.0565 0.0495 0.3636 0.0204 0.0483 0.0649]\n",
      " [0.0089 0.0081 0.0333 0.0295 0.3412 0.0237 0.002 ]\n",
      " [0.119  0.0901 0.0996 0.126  0.1722 0.2368 0.3369]\n",
      " [0.0063 0.0126 0.0196 0.0098 0.0064 0.0132 0.0012]]\n",
      "Matrix read from file:\n",
      "[ 74000.  56000.  10500.  25000.  17500. 196000.   5000.]\n",
      "new_eps: 0.7607876896588854\n",
      " Iteration                    x1                    x2                    x3                     x4                    x5                     x6                    x7               diff_x1               diff_x2               diff_x3               diff_x4               diff_x5                diff_x6              diff_x7             total_diff\n",
      "         0     0.000000000000000     0.000000000000000     0.000000000000000      0.000000000000000     0.000000000000000      0.000000000000000     0.000000000000000                   NaN                   NaN                   NaN                   NaN                   NaN                    NaN                  NaN                    NaN\n",
      "         1 74000.000000000000000 56000.000000000000000 10500.000000000000000  25000.000000000000000 17500.000000000000000 196000.000000000000000  5000.000000000000000 74000.000000000000000 56000.000000000000000 10500.000000000000000 25000.000000000000000 17500.000000000000000 196000.000000000000000 5000.000000000000000 384000.000000000000000\n",
      "         2 89344.149999999994179 77730.449999999997090 26708.050000000002910  72334.650000000008731 30325.550000000002910 265158.200000000011642  9327.799999999999272 15344.149999999994179 21730.449999999997090 16208.050000000002910 47334.650000000008731 12825.550000000002910  69158.200000000011642 4327.799999999999272 186928.850000000005821\n",
      "         3 94681.189534999997704 87714.509720000001835 37577.262640000000829 100520.489224999997532 38598.012419999999111 296563.812365000019781 11479.994285000000673  5337.039535000003525  9984.059720000004745 10869.212639999997918 28185.839224999988801  8272.462419999996200  31405.612365000008140 2152.194285000001400  96206.420190000004368\n",
      "         4 97091.939738452492747 92573.110276813997189 43867.822016876496491 115457.001829360495321 43490.991572967497632 312318.914463103516027 12598.755054539500634  2410.750203452495043  4858.600556813995354  6290.559376876495662 14936.512604360497789  4892.979152967498521  15755.102098103496246 1118.760769539499961  50263.264762113976758\n",
      "         5 98291.606280832129414 95033.213593651307747 47314.509334479414974 123202.513705042394577 46247.022591623688641 320502.383639799372759 13185.458862344024965  1199.666542379636667  2460.103316837310558  3446.687317602918483  7745.511875681899255  2756.031018656191009   8183.469176695856731  586.703807804524331  26378.173055658335215\n",
      "         6 98907.240092861233279 96305.309952373194392 49160.587519223248819 127213.720346135523869 47756.373159394832328 324796.118375662306789 13493.839587381018646   615.633812029103865  1272.096358721886645  1846.078184743833845  4011.206641093129292  1509.350567771143687   4293.734735862934031  308.380725036993681  13856.481025259025046\n",
      "         7 99226.607012931810459 96969.570525943825487 50139.590452433170867 129296.739038217609050 48569.329968705293140 327053.836124680354260 13655.946651037556876   319.366920070577180   664.260573570631095   979.002933209922048  2083.018692082085181   812.956809310460812   2257.717749018047471  162.107063656538230   7278.430740918262018\n",
      "         8 99393.062085878933431 97317.849061135741067 50656.418422303111583 130381.627983809376019 49002.815682147927873 328240.892308474110905 13741.129712877323982   166.455072947122972   348.278535191915580   516.827969869940716  1084.888945591766969   433.485713442634733   1187.056183793756645   85.183061839767106   3822.175482676904721\n",
      "         9 99480.034454340391676 97500.722367379232310 50928.654459532139299 130947.974157683580415 49232.541706830052135 328864.691748830198776 13785.874099122878761    86.972368461458245   182.873306243491243   272.236037229027716   566.346173874204396   229.726024682124262    623.799440356087871   44.744386245554779   2006.697737091948511\n",
      "        10 99525.544976347940974 97596.780771507037571 51071.882493387376599 131244.117671045300085 49353.825761989421153 329192.341585438523907 13809.370339970671921    45.510522007549298    96.058404127805261   143.228033855237300   296.143513361719670   121.284055159369018    327.649836608325131   23.496240847793160   1053.370605967798838\n",
      "        11 99549.382246032197145 97647.235878807652625 51147.183267031599826 131399.151049087435240 49417.709019109963265 329364.380273773800582 13821.706259331102046    23.837269684256171    50.455107300615055    75.300773644223227   155.033378042135155    63.883257120542112    172.038688335276674   12.335919360430125    552.884393487478519\n",
      "        12 99561.875486990567879 97673.733529246717808 51186.753100017129327 131480.376490728638601 49451.309813675674377 329454.692506228806451 13828.181957385171700    12.493240958370734    26.497650439065183    39.569832985529501    81.225441641203361    33.600794565711112     90.312232455005869    6.475698054069653    290.174891098955413\n",
      "        13 99568.426035537515418 97687.647064064833103 51207.539634350425331 131522.955215324531309 49468.967402866714110 329502.095857363543473 13831.581050644632342     6.550548546947539    13.913534818115295    20.786534333296004    42.578724595892709    17.657589191039733     47.403351134737022    3.399093259460642    152.289375879488944\n",
      "        14 99571.861652738007251 97694.951830298916320 51218.456341535274987 131545.283311551815132 49478.241693390082219 329526.975145172909833 13833.365128930872743     3.435617200491834     7.304766234083218    10.916707184849656    22.328096227283822     9.274290523368109     24.879287809366360    1.784078286240401     79.922843465683400\n",
      "        15 99573.663909320981475 97698.786496787186479 51224.188527095080644 131556.994965561025310 49483.111239381847554 329540.032291373703629 13834.301499130011507     1.802256582974223     3.834666488270159     5.732185559805657    11.711654009210179     4.869545991765335     13.057146200793795    0.936370199138764     41.943825031958113\n",
      "        16 99574.609463365268311 97700.799356620293111 51227.197983749560080 131563.139058572938666 49485.667532034145552 329546.884788604802452 13834.792938258935465     0.945554044286837     2.012859833106631     3.009456654479436     6.144093011913355     2.556292652297998      6.852497231098823    0.491439128923957     22.012192556107038\n",
      "        17 99575.105593653512187 97701.855867133213906 51228.777814491768368 131566.362702142097987 49487.009311395842815 329550.480996590922587 13835.050857708636613     0.496130288243876     1.056510512920795     1.579830742208287     3.223643569159321     1.341779361697263      3.596207986120135    0.257919449701149     11.552021910050826\n",
      "        18 99575.365928529587109 97702.410385255629080 51229.607090877092560 131568.054194908647332 49487.713551625944092 329552.368287443881854 13835.186218588110933     0.260334876074921     0.554518122415175     0.829276385324192     1.691492766549345     0.704240230101277      1.887290852959268    0.135360879474320      6.062514112898498\n",
      "        19 99575.502540169545682 97702.701419844815973 51230.042365270768641 131568.941793179139495 49488.083160424866946 329553.358737115457188 13835.257257882223712     0.136611639958574     0.291034589186893     0.435274393676082     0.887598270492163     0.369608798922854      0.990449671575334    0.071039294112779      3.181616657924678\n",
      "        20 99575.574229740828741 97702.854163868949399 51230.270824464969337 131569.407570815877989 49488.277138692923472 329553.878525084350258 13835.294540091677845     0.071689571283059     0.152744024133426     0.228459194200695     0.465777636738494     0.193978268056526      0.519787968893070    0.037282209454133      1.669718872759404\n",
      "        21 99575.611850988556398 97702.934327489245334 51230.390730431543489 131569.651999252615497 49488.378941012488212 329554.151310123037547 13835.314106132482266     0.037621247727657     0.080163620295934     0.119905966574152     0.244428436737508     0.101802319564740      0.272785038687289    0.019566040804420      0.876272670391700\n",
      "        22 99575.631594145233976 97702.976398777856957 51230.453661228057172 131569.780271392490249 49488.432367763423827 329554.294468066771515 13835.324374540188728     0.019743156677578     0.042071288611623     0.062930796513683     0.128272139874753     0.053426750935614      0.143157943733968    0.010268407706462      0.459870484053681\n",
      "Approximate solution: [ 99575.63159415  97702.97639878  51230.45366123 131569.78027139\n",
      "  49488.43236776 329554.29446807  13835.32437454]\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "A = read_matrix_from_file('FXP_input_A.txt')\n",
    "B = read_matrix_from_file('FXP_input_B.txt')\n",
    "\n",
    "# Initial guess (zero vector or any other initial guess)\n",
    "initial_guess = np.zeros(len(B))\n",
    "\n",
    "# Call the function\n",
    "solution = fixed_point_matrix_iteration(A, B, initial_guess, q=np.linalg.norm(A, ord=1), eps=10, norm=1)\n",
    "print(\"Approximate solution:\", solution)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
