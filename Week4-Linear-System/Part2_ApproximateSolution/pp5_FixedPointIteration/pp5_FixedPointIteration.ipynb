{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "4013dff3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fractions import Fraction\n",
    "from typing import Tuple, Union\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "pd.set_option('display.precision', 12)  # Increase decimal precision\n",
    "pd.set_option('display.width', 300)     # Wider display\n",
    "pd.set_option('display.max_columns', None)  # Show all column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "id": "7ec97cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_matrix(filename, convert_fractions=False):\n",
    "    \"\"\"\n",
    "    Reads a matrix from a text file and returns it as a NumPy array.\n",
    "    Supports fractional entries if present.\n",
    "    \"\"\"\n",
    "    matrix = []\n",
    "\n",
    "    with open(filename, 'r') as f:\n",
    "        for line in f:\n",
    "            tokens = line.strip().split()\n",
    "            if not tokens:\n",
    "                continue\n",
    "\n",
    "            row = []\n",
    "            for token in tokens:\n",
    "                if '/' in token:\n",
    "                    # convert fractions if any includes fraction sign\n",
    "                    val = Fraction(token)\n",
    "                    row.append(float(val) if convert_fractions else val)\n",
    "                else:\n",
    "                    # parse as float directly\n",
    "                    row.append(float(token))\n",
    "\n",
    "            matrix.append(row)\n",
    "            \n",
    "    dtype = float if convert_fractions else object\n",
    "    return np.array(matrix, dtype=dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "f7ca10db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def output_matrix(X: np.ndarray, precision: int = 12):\n",
    "    \"\"\"\n",
    "    Prints a NumPy array (vector or matrix) in a clean tabular format using pandas.\n",
    "    \n",
    "    Parameters:\n",
    "    - X: np.ndarray, 1D or 2D array.\n",
    "    - precision: number of decimal places to round floats to.\n",
    "    \"\"\"\n",
    "    # Wrap 1D arrays into a 2D DataFrame for consistent display\n",
    "    if X.ndim == 1:\n",
    "        df = pd.DataFrame(X, columns=[\"value\"])\n",
    "    elif X.ndim == 2:\n",
    "        df = pd.DataFrame(X)\n",
    "    else:\n",
    "        raise ValueError(\"Only 1D or 2D arrays are supported.\")\n",
    "    \n",
    "    # Round floats\n",
    "    # df = df.round(precision)\n",
    "    # Print without index/header for cleaner look\n",
    "    print(df.to_string(index=False, header=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ebf0562",
   "metadata": {},
   "source": [
    "Lặp đơn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "d641f129",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_norm (A: np.ndarray):\n",
    "    tmp = np.abs(A);\n",
    "    print(\"Norm column: \", np.linalg.norm(tmp, ord=1))\n",
    "    print(\"Norm 2: \", np.linalg.norm(tmp, ord=2))\n",
    "    print(\"Norm row: \", np.linalg.norm(tmp, ord=np.inf))\n",
    "    print(\"Norm max: \", 3*np.max(tmp))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "907da1e6",
   "metadata": {},
   "source": [
    "# Thuật toán"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "id": "0e8be65d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fixed_point_matrix_iteration(A, B, initial_values, q, eps, eta, norm):\n",
    "    \"\"\"\n",
    "    Perform fixed-point iteration for system of linear equations using x_new = Ax + B\n",
    "    \n",
    "    Parameters:\n",
    "    A (numpy.ndarray): Coefficient matrix\n",
    "    B (numpy.ndarray): Constant vector\n",
    "    initial_values (numpy.ndarray): Initial guess for x\n",
    "    q (float): Contraction coefficient\n",
    "    eps (float): Tolerance for convergence\n",
    "    norm (int): Type of norm to use (1 for L1 norm, -1 for max norm)\n",
    "    \n",
    "    Returns:\n",
    "    numpy.ndarray: Solution vector\n",
    "    \"\"\"\n",
    "    if (eps is None) == (eta is None):\n",
    "        raise ValueError(\"Specify exactly one of eps (exact) or eta (relative)\")\n",
    "    \n",
    "    if norm == 1:\n",
    "        vec_norm = lambda x: np.sum(np.abs(x))\n",
    "    elif norm == -1:\n",
    "        vec_norm = lambda x: np.max(np.abs(x))\n",
    "    \n",
    "    n = len(initial_values)\n",
    "    values = np.array(initial_values)\n",
    "    results = [[0] + initial_values.tolist()]\n",
    "\n",
    "    #Calculate the shrinking speed q:\n",
    "    new_eps = (eps if eps is not None else eta) * (1-q) / q\n",
    "    print(f\"new_eps: {new_eps:.12f}\")\n",
    "\n",
    "    while True:\n",
    "        # Calculate new values using matrix operation x_new = Ax + B\n",
    "        new_values = np.dot(A, values) + B\n",
    "        \n",
    "        # Calculate the differences\n",
    "        if eps is not None:\n",
    "            total_diff = vec_norm(new_values - values)\n",
    "        else:\n",
    "            total_diff = vec_norm(new_values - values) / vec_norm(new_values)\n",
    "        \n",
    "        # Append results\n",
    "        results.append(new_values.tolist() + [total_diff])\n",
    "        values = new_values\n",
    "        \n",
    "        # Check for convergence\n",
    "        if total_diff < new_eps:\n",
    "            break\n",
    "        \n",
    "    columns = [f'x{j+1}' for j in range(n)] + ['total_diff']\n",
    "    df = pd.DataFrame(results, columns=columns)\n",
    "    df.index.name = \"Iteration\"\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f9347d9",
   "metadata": {},
   "source": [
    "# Kết quả"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "fa869b50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Matrix A:\n",
      "0.1588 0.0064 0.0025 0.0304 0.0014 0.0083 0.1594\n",
      "0.0057 0.2645 0.0436 0.0099 0.0083 0.0201 0.3413\n",
      "0.0264 0.1506 0.3557 0.0139 0.0142 0.0070 0.0236\n",
      "0.3299 0.0565 0.0495 0.3636 0.0204 0.0483 0.0649\n",
      "0.0089 0.0081 0.0333 0.0295 0.3412 0.0237 0.0020\n",
      "0.1190 0.0901 0.0996 0.1260 0.1722 0.2368 0.3369\n",
      "0.0063 0.0126 0.0196 0.0098 0.0064 0.0132 0.0012\n",
      "Norm column:  0.9292999999999998\n",
      "Norm 2:  0.7286368954281354\n",
      "Norm row:  1.1806\n",
      "Norm max:  1.0908\n",
      "\n",
      "Matrix B:\n",
      " 74000.0\n",
      " 56000.0\n",
      " 10500.0\n",
      " 25000.0\n",
      " 17500.0\n",
      "196000.0\n",
      "  5000.0\n"
     ]
    }
   ],
   "source": [
    "#Original matrix Ax=B\n",
    "A = input_matrix('FXP_input_A.txt', convert_fractions=True)\n",
    "B = input_matrix('FXP_input_B.txt', convert_fractions=True).flatten() #remove flatten if B is multi-column matrix\n",
    "\n",
    "print(\"\\nMatrix A:\"); output_matrix(A)\n",
    "check_norm(A)\n",
    "print(\"\\nMatrix B:\"); output_matrix(B)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "id": "c413fd2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new_eps: 0.000000076079\n",
      "                           x1                  x2                  x3                   x4                  x5                   x6                  x7           total_diff\n",
      "Iteration                                                                                                                                                                   \n",
      "0              0.000000000000      0.000000000000      0.000000000000       0.000000000000      0.000000000000       0.000000000000      0.000000000000       0.000000000000\n",
      "1          74000.000000000000  56000.000000000000  10500.000000000000   25000.000000000000  17500.000000000000  196000.000000000000   5000.000000000000  384000.000000000000\n",
      "2          89344.149999999994  77730.449999999997  26708.050000000003   72334.649999999994  30325.550000000003  265158.200000000012   9327.799999999999  186928.849999999977\n",
      "3          94681.189534999998  87714.509720000002  37577.262640000001  100520.489224999998  38598.012419999999  296563.812365000020  11479.994284999999   96206.420190000019\n",
      "4          97091.939738452493  92573.110276813997  43867.822016876504  115457.001829360495  43490.991572967498  312318.914463103516  12598.755054539501   50263.264762113991\n",
      "5          98291.606280832129  95033.213593651308  47314.509334479415  123202.513705042395  46247.022591623689  320502.383639799373  13185.458862344025   26378.173055658328\n",
      "6          98907.240092861248  96305.309952373194  49160.587519223249  127213.720346135524  47756.373159394832  324796.118375662249  13493.839587381017   13856.481025258980\n",
      "7          99226.607012931810  96969.570525943825  50139.590452433171  129296.739038217609  48569.329968705293  327053.836124680296  13655.946651037559    7278.430740918251\n",
      "8          99393.062085878933  97317.849061135741  50656.418422303112  130381.627983809391  49002.815682147921  328240.892308474053  13741.129712877324    3822.175482676910\n",
      "9          99480.034454340392  97500.722367379232  50928.654459532147  130947.974157683595  49232.541706830052  328864.691748830199  13785.874099122877    2006.697737092019\n",
      "10         99525.544976347941  97596.780771507038  51071.882493387384  131244.117671045329  49353.825761989421  329192.341585438582  13809.370339970670    1053.370605967872\n",
      "11         99549.382246032197  97647.235878807653  51147.183267031600  131399.151049087464  49417.709019109971  329364.380273773801  13821.706259331104     552.884393487424\n",
      "12         99561.875486990582  97673.733529246732  51186.753100017129  131480.376490728639  49451.309813675682  329454.692506228806  13828.181957385172     290.174891098954\n",
      "13         99568.426035537515  97687.647064064833  51207.539634350418  131522.955215324560  49468.967402866714  329502.095857363543  13831.581050644632     152.289375879474\n",
      "14         99571.861652738007  97694.951830298916  51218.456341535275  131545.283311551815  49478.241693390082  329526.975145172910  13833.365128930873      79.922843465662\n",
      "15         99573.663909320981  97698.786496787186  51224.188527095088  131556.994965561025  49483.111239381848  329540.032291373704  13834.301499130012      41.943825031965\n",
      "16         99574.609463365268  97700.799356620293  51227.197983749553  131563.139058572939  49485.667532034153  329546.884788604802  13834.792938258935      22.012192556100\n",
      "17         99575.105593653512  97701.855867133214  51228.777814491768  131566.362702142098  49487.009311395843  329550.480996590923  13835.050857708635      11.552021910049\n",
      "18         99575.365928529587  97702.410385255629  51229.607090877100  131568.054194908647  49487.713551625944  329552.368287443882  13835.186218588111       6.062514112908\n",
      "19         99575.502540169546  97702.701419844816  51230.042365270769  131568.941793179139  49488.083160424867  329553.358737115399  13835.257257882224       3.181616657859\n",
      "20         99575.574229740829  97702.854163868949  51230.270824464969  131569.407570815907  49488.277138692916  329553.878525084350  13835.294540091676       1.669718872838\n",
      "21         99575.611850988556  97702.934327489245  51230.390730431543  131569.651999252615  49488.378941012488  329554.151310123038  13835.314106132482       0.876272670372\n",
      "22         99575.631594145234  97702.976398777857  51230.453661228064  131569.780271392490  49488.432367763424  329554.294468066772  13835.324374540189       0.459870484061\n",
      "23         99575.641955207364  97702.998478370850  51230.486688950419  131569.847587366210  49488.460406466111  329554.369597636629  13835.329763469048       0.241341552601\n",
      "24         99575.647392653220  97703.010065985087  51230.504022557325  131569.882914427144  49488.475121322663  329554.409025825036  13835.332591611246       0.126656915090\n",
      "25         99575.650246217643  97703.016147270493  51230.513119503157  131569.901453984668  49488.482843746424  329554.429717856459  13835.334075835926       0.066470033051\n",
      "26         99575.651743769486  97703.019338776081  51230.517893692668  131569.911183538847  49488.486896507384  329554.440577104222  13835.334854764777       0.034883738692\n",
      "27         99575.652529687155  97703.021013699821  51230.520399235451  131569.916289620043  49488.489023413218  329554.446276077069  13835.335263550523       0.018307129818\n",
      "28         99575.652942138709  97703.021892710007  51230.521714165501  131569.918969302438  49488.490139622234  329554.449266920099  13835.335478083260       0.009607658967\n",
      "29         99575.653158594563  97703.022354019471  51230.522404250405  131569.920375607384  49488.490725413401  329554.450836526579  13835.335590671055       0.005042140610\n",
      "30         99575.653272191354  97703.022596117109  51230.522766411435  131569.921113640914  49488.491032839076  329554.451660262537  13835.335649757653       0.002646137220\n",
      "31         99575.653331807378  97703.022723171176  51230.522956475681  131569.921500963625  49488.491194177390  329554.452092562686  13835.335680766571       0.001388704428\n",
      "32         99575.653363094098  97703.022789849769  51230.523056222439  131569.921704232111  49488.491278848436  329554.452319435659  13835.335697040193       0.000728798197\n",
      "33         99575.653379513504  97703.022824843007  51230.523108570051  131569.921810908243  49488.491323284165  329554.452438499546  13835.335705580663       0.000382476474\n",
      "34         99575.653388130479  97703.022843207626  51230.523136042342  131569.921866892313  49488.491346604234  329554.452500984829  13835.335710062740       0.000200725386\n",
      "35         99575.653392652704  97703.022852845461  51230.523150459936  131569.921896272979  49488.491358842708  329554.452533777338  13835.335712414955       0.000105341518\n",
      "36         99575.653395025991  97703.022857903445  51230.523158026357  131569.921911692101  49488.491365265509  329554.452550987015  13835.335713649407       0.000055283743\n",
      "37         99575.653396271489  97703.022860557903  51230.523161997247  131569.921919784101  49488.491368636227  329554.452560018748  13835.335714297253       0.000029013145\n",
      "38         99575.653396925147  97703.022861950973  51230.523164081191  131569.921924030816  49488.491370405194  329554.452564758656  13835.335714637247       0.000015226255\n",
      "39         99575.653397268179  97703.022862682061  51230.523165174855  131569.921926259529  49488.491371333555  329554.452567246160  13835.335714815676       0.000007990791\n",
      "40         99575.653397448215  97703.022863065737  51230.523165748811  131569.921927429154  49488.491371820768  329554.452568551642  13835.335714909317       0.000004193629\n",
      "41         99575.653397542686  97703.022863267091  51230.523166050029  131569.921928042982  49488.491372076460  329554.452569236746  13835.335714958459       0.000002200810\n",
      "42         99575.653397592279  97703.022863372767  51230.523166208106  131569.921928365133  49488.491372210643  329554.452569596295  13835.335714984250       0.000001155020\n",
      "43         99575.653397618298  97703.022863428225  51230.523166291066  131569.921928534197  49488.491372281060  329554.452569784946  13835.335714997786       0.000000606104\n",
      "44         99575.653397631948  97703.022863457329  51230.523166334606  131569.921928622935  49488.491372318022  329554.452569884015  13835.335715004887       0.000000318163\n",
      "45         99575.653397639107  97703.022863472608  51230.523166357452  131569.921928669472  49488.491372337419  329554.452569935936  13835.335715008616       0.000000166870\n",
      "46         99575.653397642876  97703.022863480612  51230.523166369443  131569.921928693919  49488.491372347591  329554.452569963236  13835.335715010573       0.000000087639\n",
      "47         99575.653397644855  97703.022863484832  51230.523166375737  131569.921928706754  49488.491372352932  329554.452569977555  13835.335715011599       0.000000046013\n"
     ]
    }
   ],
   "source": [
    "# Initial guess (zero vector or any other initial guess)\n",
    "initial_guess = np.array([0, 0, 0, 0, 0, 0, 0])\n",
    "q = np.linalg.norm(np.abs(A), ord=1)\n",
    "eps = 1e-6\n",
    "eta = None\n",
    "norm = 1\n",
    "\n",
    "# Call the function\n",
    "df_history = fixed_point_matrix_iteration (A, B, initial_guess, q, eps, eta, norm)\n",
    "print(df_history)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "id": "a642f207",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Approximate solution:\n",
      "x1     99575.653397644855\n",
      "x2     97703.022863484832\n",
      "x3     51230.523166375737\n",
      "x4    131569.921928706754\n",
      "x5     49488.491372352932\n",
      "x6    329554.452569977555\n",
      "x7     13835.335715011599\n"
     ]
    }
   ],
   "source": [
    "solution_series = df_history.filter(regex=r'^x\\d+$').iloc[-1]\n",
    "print(\"Approximate solution:\"),\n",
    "print(solution_series.to_string())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
